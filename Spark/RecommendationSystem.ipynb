{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d079a63-2f45-4949-998b-dc513d9637da",
   "metadata": {},
   "source": [
    "# Configured Spark, PostgreSQL and MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd062a6-722f-4369-9376-054a62a7cb2c",
   "metadata": {},
   "source": [
    "##### 1. PySpark Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7457f6-5f6c-4bfe-866e-6a3bfc43d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f70a-3b40-4ef5-814c-e3a0873b8974",
   "metadata": {},
   "source": [
    "##### 2. Configuring SparkSession for PostgreSQl and MongoDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e55ba6-18db-4ea7-8e72-581326509633",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"restaurant\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.jars\", \"/Users/deependrashekhawat/jars/postgresql-42.2.21.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426e948-1ee1-4d8a-9bcc-6aafa01e9fd5",
   "metadata": {},
   "source": [
    "# Processing Restaurant Data from PostgreSQL DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018099b-02db-46e9-9488-be4c13751d9b",
   "metadata": {},
   "source": [
    "##### 1. Creating cursor and executing SQL query to fetch all the restaurant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba21ca4-a62f-465f-9470-8af80071b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host=\"localhost\", database=\"testrestaurant\", user=\"postgres\", password=\"Welcome@1\", port=5436)\n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b05110-bec9-41cc-833f-e98e72e5cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.execute(\"\"\"\n",
    "SELECT rs.restaurant_id, restaurant_name, street, city, state, postal_code, latitude, longitude, stars, review_count, cuisine_name\n",
    "FROM restaurantcuisine rs\n",
    "JOIN restaurants r ON (rs.restaurant_id = r.restaurant_id)\n",
    "JOIN address a ON (r.address_id = a.address_id)\n",
    "JOIN cuisines c ON (rs.cuisine_id = c.cuisine_id);\n",
    "\"\"\")\n",
    "restaurantCuisineRaw = curr.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411901e-0c8a-4a51-b3d7-013036f24e5e",
   "metadata": {},
   "source": [
    "##### 2. Creating a Raw DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2dd044-9e8e-40a7-bc92-f5a6e9db113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"restaurant_id\", \"restaurant_name\", \"street\", \"city\", \"state\", \\\n",
    "           \"postal_code\", \"latitude\", \"longitude\", \"stars\", \"review_count\", \"cuisine_name\"]\n",
    "dfRestCusRaw = my_spark.createDataFrame(data=restaurantCuisineRaw, schema = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a9d77-2072-4d78-9a5e-f420e9bff002",
   "metadata": {},
   "source": [
    "##### 3. Processing Restaurant data to fetch top 10 for each cuisine based on City and State."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d989397-c4ab-4a75-9b2a-52f59ac685f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy(\"city\", \"state\", \"cuisine_name\")\\\n",
    "                    .orderBy(F.col(\"stars\").desc(), F.col(\"review_count\").desc())\n",
    "\n",
    "max_number_of_rows_per_partition = 10\n",
    "\n",
    "dfRestCusProcessed = dfRestCusRaw.withColumn(\"row_number\", F.row_number().over(window_spec))\\\n",
    "  .filter(F.col(\"row_number\") <= max_number_of_rows_per_partition)\\\n",
    "  .drop(\"row_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a206e-5c51-4762-bd73-bb663dc8becb",
   "metadata": {},
   "source": [
    "# City, State and Cuisine based Top 10 Restaurant Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1be922c-fa20-4ac2-a537-2cc07ae589cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCityCusRest = dfRestCusProcessed.groupBy(\"city\", \"state\", \"cuisine_name\") \\\n",
    "                    .agg(F.collect_list(F.struct(\"restaurant_id\", \"restaurant_name\", \"street\", \"city\", \"state\", \\\n",
    "                           \"postal_code\", \"latitude\", \"longitude\", \"stars\", \"review_count\", \"cuisine_name\")).alias(\"restaurants\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed4d1b7-2083-43ef-b7df-f37ef1a93376",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCityCusRest.write \\\n",
    ".format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    ".mode(\"overwrite\") \\\n",
    ".option(\"spark.mongodb.output.uri\", \"mongodb://localhost:27017/hungryApp.topCityRestaurants\") \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15954d48-d3af-4ad9-afde-79acd42f604d",
   "metadata": {},
   "source": [
    "# User preference based Restaurant Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c9fe3-88e7-4b7f-a677-5c72fdb34c29",
   "metadata": {},
   "source": [
    "##### 1. Reading User data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c5ac5e-6be4-48af-87ca-9bca1e8260de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUserRaw = my_spark.read \\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "    .option(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/hungryApp.users\") \\\n",
    "    .load()\n",
    "\n",
    "dfUser = dfUserRaw.select(\"_id\", \"city\", \"state\", F.explode(\"preference\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dabb57-9b92-4f63-a9df-9b39b2a968e5",
   "metadata": {},
   "source": [
    "##### 2. Joining User and City Cusine Restaurant DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26859518-32e4-42d1-9e37-777231b06172",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUserJoinCityCusRest = dfUser \\\n",
    "    .select(\"_id\", F.initcap(\"city\").alias(\"city\"), \"state\", F.initcap(\"col\").alias(\"cuisine_name\")) \\\n",
    "    .join(dfCityCusRest, [\"cuisine_name\", \"city\", \"state\"], \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def0355-5145-4c74-93ca-c4bb48501139",
   "metadata": {},
   "source": [
    "##### 3. Writing top 10 restaurant recommendation for a user to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4003ec-fa65-4a60-a008-d72b22795d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUserJoinCityCusRest \\\n",
    ".groupBy(\"_id\") \\\n",
    ".agg(F.collect_list(F.struct(\"cuisine_name\", \"restaurants\")).alias(\"cuisines\")) \\\n",
    ".write \\\n",
    ".format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    ".mode(\"overwrite\") \\\n",
    ".option(\"spark.mongodb.output.uri\", \"mongodb://localhost:27017/hungryApp.restaurantRecommendation\") \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27d182-37a9-4e32-bb4a-c18ff8e8cc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
